---
title: "Introduction to shinymeta"
author: "Joe Cheng"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to shinymeta}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  comment = "#>"
)
library(shiny)
library(shinymeta)
```

## Motivation: Interactivity or reproducibility, pick one

Since its introduction in 2012, Shiny has become a mainstay of the R ecosystem, providing a solid foundation for building interactive artifacts of all kinds. But that interactivity has always come at a significant cost to reproducibility, as actions performed in a Shiny app are not easily captured for later analysis and replication.

In 2016, Shiny gained a "bookmarkable state" feature that makes it possible to snapshot and restore application state via URL. But this feature, though useful, doesn't completely solve the reproducibility problem, as the actual program logic is still locked behind a user interface.

The goal of shinymeta is to allow Shiny app authors to present their users with not only the traditional outputs of their analysis (plots, tables, etc.), but also the exact R source code necessary to reproduce that analysis, without any trace of Shiny boilerplate.

[Screenshot or diagram]

An app author might have any number of reasons for wanting to expose such R code to their users:

* **Teaching:** For classroom use, a student might use a Shiny app interactively to gain intuitive understanding of a statistical concept, then use the code to learn how to use the corresponding function from their own R scripts.
* **Transparency:** In research, your methods are just as important as your results. If you want your Shiny app's users to have the ability to audit your methods, it's much easier for them to do so using a reproducible script.
* // TODO: Gateway drug to coding / Enabling
* **Automation:** Shiny apps often use data that changes over time: stock quotes, sensor readings, centralized databases, etc. By providing users with reproducible R code, you enable them to take that logic into other workflows, such as creating a [periodic R Markdown email using RStudio Connect](https://docs.rstudio.com/connect/1.7.4/user/r-markdown-schedule.html).
* **Permanence:** Using a Shiny app can have an ephemeral feeling to it; what happens in the future if the server goes down, or the app's features change? With a reproducible report, your user can download a more permanent artifact that can be saved locally.
* **Scaffolding:** Some Shiny apps don't answer a lot of questions on their own, but instead provide access data that might otherwise be difficult for users to acquire; for example, very large data sets often have an interactive front end that analysts can use to download CSV files that are generated on the fly. With shinymeta, such apps could also offer code snippets for downloading the same data programatically, making the act of downloading the data reproducible.

## Design and implementation

Our goal is to make it possible for a Shiny app to serve two purposes:

1. Serving an interactive web application, i.e. its usual purpose
2. Exposing the essential logic that drives one or more of the app's outputs, in the form of .R or .Rmd

First, can we stop for a moment and recognize that this is a pretty daunting challenge? As it is, Shiny works pretty hard to provide a natural syntax for writing interactive applications. And now, these apps have to not only work, they also need to expose their "essential logic" in a way that can be used outside of Shiny.

Perhaps in the future, someone smarter than your humble author will come up with a silver bullet for achieving perfect reproducibility from any Shiny app with no effort from the app author. But for today, we're stuck with difficult tradeoffs between:

1. **Quality of output:** Does the generated code look clean, like a human would write it; or is it awkwardly structured and/or contain random boilerplate?
2. **Implementation effort:** How hard is it to add code generation to your app?
3. **Generality:** Can code generation features be added to _any_ Shiny app, or only apps that follow certain conventions? Does it work as well for large, complex apps as for small ones?

### Approach 1: Copy and paste

> Quality of output: \*\*\*\*\*
>
> Ease of learning: \*\*\*\*
>
> Ease of implementation: \*\* (but highly variable)
>
> Generality: \*\*

The simplest approach is to simply duplicate your logic. You have an `app.R` file that contains your Shiny app, and a separate `script.R` or `report.Rmd` file that contains the same logic in linear form (i.e. minus any of the structure that Shiny imposes). The `script.R` or `report.Rmd` contains placeholders that will be replaced by input values selected by the user.

// TODO: Example

This approach is easy to understand, but it means that you are stuck maintaining a parallel codebase that you must manually keep in sync; over the long term, this can be a source of not only tedium but also bugs. On the plus side, because you're maintaining `script.R`/`report.Rmd` by hand, the level of code quality is limited only by your own skill.

### Approach 2: Mechanical transformation (scriptgloss)

> Quality of output: \**
>
> Ease of learning: \*\*\*
>
> Ease of implementation: \*\*\*\*
>
> Generality: \*\*

This approach automatically transforms your reactives, outputs, and observers into linearized code, using predefined algorithms/heuristics. You as the app author are neither required nor able to influence the code generation process very much. The nice thing about this is how little effort it isâ€”you can add scriptgloss to your app in a couple of minutes!

The price you pay for all this automation is that the generated code looks pretty unnatural, with some Shiny-related wires sticking out. Plus, there are several common situations that will lead to the script not working; then the onus is on either the app author to gain a deeper understanding of scriptgloss and restructure the app to suit, or on the user to take the slightly broken code and fix it.

### Approach 3: Metaprogramming (shinymeta)

> Quality of output: \*\*\*\*
>
> Ease of learning: \*\*
>
> Ease of implementation: \*\*\*
>
> Generality: \*\*\*\*\*

Of these three techniques, metaprogramming is by far the most conceptually challenging to get started with. In exchange for climbing the considerable learning curve, you get much more control over how the code output is generated. We also believe (but can't yet prove) that this approach can scale to larger, more complex apps, including ones that use Shiny modules.

The rest of this document will explain the shinymeta approach.

## shinymeta in action

Let's cut to the chase by looking at a finished example of a shinymeta app.

This app is an interactive demonstration of polynomial regression. You can choose your independent and dependent variables, and the desired degree. Less obviously, you can click on individual data points to mark them as outliers and exclude them from the model.

[Screenshot or maybe movie]

It feels just like a normal Shiny app, until you press the "R Code" button. Here's the output we've been talking about: the logic behind the app. We can copy this code into a new R session and it produces exactly the same output:

[Screenshot]

In order to achieve this, we had to use the shinymeta package and take special care in crafting the logic of this app. A typical reactive expression might look like this (where `data_kept` and `model_fit` are also reactive expressions):

```r
data_fitted <- reactive({
  modelr::add_predictions(data_kept(), model_fit())
})
```

But the version used in this shinymeta-enabled app looks like this:

```r
data_fitted <- metaReactive({
  modelr::add_predictions(!!data_kept(), !!model_fit())
})
```

The `reactive` function has been changed to `metaReactive`, and `!!` prefixes have been added to the reactive expression reads. We'll get into the specifics in a moment, but first, we need to take a step back and talk about the idea that puts the "meta" in "shinymeta".

## Metaprogramming

In traditional programming, your code manipulates data; say, adding two vectors together, or filtering a data frame, or converting a matrix of numbers to an RGB image.

In metaprogramming, your code manipulates code! This may seem strange, since we normally think of the code we write as being simply input for the R compiler/interpreter, which then faithfully executes our commands. But actually, R is capable of treating its own code as data, to be examined, modified, executed, printed.

What do we mean by "code as data"? Well, here's a number as data:

```{r}
num_data <- 3 + 5
num_data
```

Here's a string as data:

```{r}
str_data <- "3 + 5"
str_data
```

Note that the result isn't `8`, because the `3 + 5` is quoted using `"..."`.

And here, finally, is _code_ as data:

```{r}
code_data <- quote(3 + 5)
code_data
eval(code_data)
```

This looks a lot like the string example, but instead of quoting using `"..."`, we quote using `quote(...)`.

### Creating code objects using `quote()`

You can quote any syntactically valid R expression using `quote`:

```{r}
quote(print(letters))
quote(lm.D9 <- lm(weight ~ group))
quote(mtcars %>% dplyr::filter(hp >= 200))
```

If you have more than one statement/expression, you can use code blocks (`{...}`):

```{r}
quote({
  p <- ggplot(diamonds, aes(carat, price))
  p <- p + geom_point()
  p
})
```

Now, we could've used `"..."` to turn these expressions into strings instead of using `quote(...)` to turn them into code blocks. But there are significant advantages to using the latter.

For one thing, `quote` does some basic syntax error checking for you. The expression `print(*10)` isn't valid R, yet it's a totally valid string. `quote(...)` will rightfully reject it.

```{r}
"print(*10)"
```
```{r error=TRUE}
quote(print(*10))
```

It's not impossible to construct a syntactically invalid code object, but it's much harder to do so accidentally than if we were using strings to represent our code.

There are more advantages to using code objects when we start talking about manipulation, not just creation. More on that below, but first let's bring it back to Shiny.

## Creating a new class of reactive objects

Most of the essential logic in Shiny apps is locked up in reactive expressions, output renderers, and observers. We need to make it possible to have these reactive objects work as normal when the app is running, but to also make it possible to "export" their code bodies when it's time to generate a reproducible script or report.

Let's focus on reactive expressions first. `shiny::reactive` doesn't have an "export code" feature, so shinymeta includes a function called `metaReactive` that acts as a replacement:

```{r}
library(dplyr)

# Non-meta
r <- reactive({
  mtcars %>% filter(hp >= input$min_hp)
})

# Meta
mr <- metaReactive({
  mtcars %>% filter(hp >= input$min_hp)
})
```

To help you understand how `metaReactive` works, we need to discuss a couple of lower-level functions that it builds on top of.

The first is a function called `metaExpr`. At first glance, this function does... nothing. It just returns whatever you give it, like `base::identity`:

```{r}
metaExpr(1 + 1)
metaExpr(matrix(1:4, 2, 2))
```

`metaExpr` only starts being useful when we introduce the second function, `metaMode()`. It's technically a function, but conceptually it's like a global variable that's either `TRUE` or `FALSE`. Call it with no arguments to get the current value, or pass it `TRUE` or `FALSE` to set it.

```{r}
metaMode()        # Initially FALSE
metaMode(TRUE)    # Set it to TRUE
metaMode()        # Yep, it's TRUE
```

When `metaMode` is `TRUE`, the behavior of `metaExpr` changes.

```{r}
metaMode(FALSE)
metaExpr(1 + 1)
metaMode(TRUE)
metaExpr(1 + 1)
```

Instead of getting the result, now we get the code!

To sum up the relationship of these two functions: `metaExpr` acts like `identity`, unless `metaMode` is true, in which case it acts like `quote`.



<!--

Dividing shinymeta into subproblems:

1. Dual-purpose reactive objects (`metaExpr` and `withMetaMode`)
    1. Dual-Purpose
        - Use `metaExpr` to wrap code that needs to play these dual roles.
        - Use `withMetaMode` to control whether `metaExpr` returns unevaluated code, or evaluates the code and returns the results.
              - It's surprising that this works by setting global state, why isn't this just an option you pass to `metaExpr`? This'll be answered later.
        - You'll rarely use these primitives directly, but it's important that you understand that there are these two modes.
    2. Reactive
        - `metaReactive` is a version of `reactive` that implicitly wraps your code in `metaExpr`--that works great assuming you want the entire code body to be wrapped. (Use `metaReactive2` if you want to control what code gets `metaExpr`'d.)
        - Why not just `reactive(metaExpr(...))`? Because caching. And if that doesn't make sense to you, don't worry about it--just know that it's always wrong to put `metaExpr` inside of `reactive`, `observe`, `output$foo`.

```{r}
downloads <- metaReactive({
  cran_downloads(
    package = input$packages, 
    from    = from(),
    to      = Sys.Date() - 1
  )
})
```

r2 <- metaReactive({

})

2. Using annotation to combine/compose meta reactive objects (`!!`)
    - Based on unquoting, a concept that exists in base R (see `bquote`) and more recently was (un-)popularized by the `!!` operator from the tidyverse
    - 




3. Global optimization/clean-up (`expandCode`)

4. Displaying/reporting/bundling


-->
